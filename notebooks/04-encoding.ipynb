{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Model Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial introduces a typical encoding framework for mapping different features onto human brain activity during natural language comprehension. From previous notebooks, two types of features are obtained based on the stimulus transcript: syntactic features from spacy.io ([Honnibal et al., 2020](https://github.com/explosion/spaCy)) and contextual word embeddings from GPT-2 ([Radford et al., 2019](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)). Encoding models ([Naselaris et al., 2011](https://www.sciencedirect.com/science/article/pii/S1053811910010657?via%3Dihub)) map those features onto brain activity. They are estimated using ridge regression implemented in the [Himalaya](https://gallantlab.org/himalaya/index.html) package ([Dupr√© La Tour et al., 2022](https://doi.org/10.1016/j.neuroimage.2022.119728)).\n",
    "\n",
    "Acknowledgments: This tutorial draws heavily on the [encling tutorial](https://github.com/snastase/encling-tutorial/blob/main/encling_tutorial.ipynb) by Samuel A. Nastase.\n",
    "\n",
    "______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll import some general-purpose Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nilearn.plotting import plot_markers\n",
    "from mne_bids import BIDSPath\n",
    "\n",
    "from himalaya.backend import set_backend, get_backend\n",
    "from himalaya.ridge import RidgeCV\n",
    "from himalaya.scoring import correlation_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will set the [Himalaya backend](https://gallantlab.org/himalaya/_generated/himalaya.backend.set_backend.html#himalaya.backend.set_backend) to `torch_cuda` so we can utilize gpu to train our encoding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    set_backend(\"torch_cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load two different features. The first is syntactic features constructed using spacy.io ([Honnibal et al., 2020](https://github.com/explosion/spaCy)). The second contains contextual word embeddings generated from GPT-2 ([Radford et al., 2019](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)). The loaded features should be a numpy array with a shape of (number of tokens * feature dimensions). Note that the numbers of tokens are different for the two features because of different tokenization schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = \"/scratch/gpfs/kw1166/247/monkey-data/stimuli/%s/states.hdf5\"\n",
    "\n",
    "# Syntactic features\n",
    "with h5py.File(embedding_path % \"syntactic\", \"r\") as f:\n",
    "    syntactic_features = f[\"vectors\"][...]\n",
    "print(syntactic_features.shape)\n",
    "\n",
    "# Contextual word embeddings\n",
    "modelname, layer = 'gpt2', 6\n",
    "\n",
    "with h5py.File(embedding_path % modelname, \"r\") as f:\n",
    "    contextual_embeddings = f[f\"layer-{layer}\"][...]\n",
    "print(contextual_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also load the stimuli transcripts associated with these features. Both transcripts should contain information about the word, token, start (onset), and end (offset). The contextual word embedding transcript should also include other prediction information extracted from GPT-2, like rank, probability, and entropy. For instance, we can calculate how accurate the model is in predicting the next token in the transcript based on the `rank` column, which are integers that represents the rank of the actual token in all the possible tokens of GPT-2.\n",
    "\n",
    "Note: Check that the transcript contains the same number of tokens as the features we loaded before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_path = \"/scratch/gpfs/kw1166/247/monkey-data/stimuli/%s/transcript.tsv\"\n",
    "\n",
    "# Syntactic features transcript\n",
    "df_syntactic = pd.read_csv(transcript_path % \"syntactic\", sep='\\t', index_col=0)\n",
    "print(df_syntactic.shape)\n",
    "print(df_syntactic.head())\n",
    "\n",
    "# Contextual word embeddings transcript\n",
    "df_contextual = pd.read_csv(transcript_path % modelname, sep=\"\\t\", index_col=0)\n",
    "\n",
    "if \"rank\" in df_contextual.columns:\n",
    "    model_acc = (df_contextual[\"rank\"] == 0).mean()\n",
    "    print(f\"Model accuracy: {model_acc*100:.3f}%\")\n",
    "\n",
    "print(df_contextual.shape)\n",
    "print(df_contextual.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we extracted features, some words are split into separate tokens. Since we only have information of start and end for words, we will align the features from tokens to words for encoding models. Here, we simply average the token features across the same word. Now the features should be a numpy array with a shape of (number of words * feature dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntactic features\n",
    "aligned_syntactic = []\n",
    "for _, group in df_syntactic.groupby(\"word_idx\"): # group by word index\n",
    "    indices = group.index.to_numpy()\n",
    "    average_syntactic = syntactic_features[indices].mean(0) # average features\n",
    "    aligned_syntactic.append(average_syntactic)\n",
    "aligned_syntactic = np.stack(aligned_syntactic)\n",
    "print(aligned_syntactic.shape)\n",
    "\n",
    "# Contextual word embeddings\n",
    "aligned_embeddings = []\n",
    "for _, group in df_contextual.groupby(\"word_idx\"): # group by word index\n",
    "    indices = group.index.to_numpy()\n",
    "    average_emb = contextual_embeddings[indices].mean(0) # average features\n",
    "    aligned_embeddings.append(average_emb)\n",
    "aligned_embeddings = np.stack(aligned_embeddings)\n",
    "print(aligned_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also construct a dataframe containing words with their start and end information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_word = df_contextual.groupby(\"word_idx\").agg(dict(word=\"first\", start=\"first\", end=\"last\"))\n",
    "df_word.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need word start information for encoding, we will filter out words where the `start` column information is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_mask = df_word['start'].notna().to_numpy()\n",
    "print(sum(good_mask))\n",
    "\n",
    "aligned_syntactic = aligned_syntactic[good_mask]\n",
    "aligned_embeddings = aligned_embeddings[good_mask]\n",
    "print(aligned_syntactic.shape)\n",
    "print(aligned_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading brain data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load the ECoG data using MNE. Here, we will demonstrate loading data from our third subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_path = BIDSPath(\n",
    "    root=\"/scratch/gpfs/zzada/ecog-narratives/monkey/derivatives/ecogprep\",\n",
    "    subject=\"03\",\n",
    "    datatype=\"ieeg\",\n",
    "    description=\"highgamma\",\n",
    "    extension=\".fif\",\n",
    ")\n",
    "edf_path = edf_path.match()[0]\n",
    "\n",
    "raw = mne.io.read_raw_fif(edf_path)\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will map the start information (in seconds) of each word in the dataframe onto the brain signal data by multiplying by the sampling rate. Here the first column of `events` mark the start of each word on the brain signal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = np.zeros((len(df_word), 3), dtype=int)\n",
    "events[:, 0] = (df_word.start * raw.info['sfreq']).astype(int)\n",
    "events.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll take advantage of MNE's tools for creating epochs around stimulus events, which here are the starts (onsets) of each word, to visualize brain signal that respond to word onsets. Here, we take a fixed-width window ranging from -2 seconds to +2 seconds relative to word onset. Since the sampling rate is 512 Hz (512 samples per second), we have 2049 lags total. The ECoG data is a numpy array with the shape of (number of words * number of ECoG electrodes * number of lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = mne.Epochs(\n",
    "    raw,\n",
    "    events,\n",
    "    tmin=-2.0,\n",
    "    tmax=2.0,\n",
    "    baseline=None,\n",
    "    proj=False,\n",
    "    event_id=None,\n",
    "    preload=True,\n",
    "    event_repeated=\"merge\",\n",
    ")\n",
    "print(f\"ECoG data matrix shape: {epochs._data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll downsample the temporal resolution to 32 Hz, which reduces the number of lags to 32 * 4 = 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = epochs.resample(sfreq=32, npad='auto', method='fft', window='hamming')\n",
    "# epochs = epochs.resample(sfreq=32, npad='auto', method='polyphase')\n",
    "epochs._data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can average each electrode's signal across all words, yielding event-related potentials (ERPs) for word start (onsets). Here, we visualize how one particular electrode, `LGA10` from subject 3, respond to word onsets (Time = 0s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked = epochs.average()\n",
    "evoked = evoked.pick(\"LGA10\")\n",
    "evoked.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up feature and brain data\n",
    "\n",
    "Now we have both the features and the ECoG data ready. We plan to fit encoding models at each electrode and for each lag, so we'll reshape our target matrix `Y` to horizontally stack both electrodes and lags along the secondg dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_data = epochs.get_data(copy=True) # Get ECoG data\n",
    "epochs_data = epochs_data.reshape(len(epochs), -1) # Reshape ECoG data\n",
    "print(f\"ECoG data matrix shape: {epochs_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also align our features with the ECoG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = df_word.iloc[epochs.selection]\n",
    "averaged_syntactic = aligned_syntactic[epochs.selection]\n",
    "averaged_embeddings = aligned_embeddings[epochs.selection]\n",
    "print(averaged_syntactic.shape)\n",
    "print(averaged_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will change the float precision to float32 for all data to take advantage of the GPU memory and computational speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = averaged_syntactic\n",
    "X2 = averaged_embeddings\n",
    "Y = epochs_data\n",
    "\n",
    "if \"torch\" in get_backend().__name__:\n",
    "    X1 = X1.astype(np.float32)\n",
    "    X2 = X2.astype(np.float32)\n",
    "    Y = Y.astype(np.float32)\n",
    "\n",
    "X1.shape, X2.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building encoding models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use ridge regression to estimate the encoding model. We create a model pipeline uisng `sklearn`, which includes a [`StandardScaler`](https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.StandardScaler.html) that standardizes features (X), and a [`RidgeCV model`](https://gallantlab.org/himalaya/_generated/himalaya.ridge.RidgeCV.html#himalaya.ridge.RidgeCV), which performs ridge regression with cross-validation over our specificed alpha values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.logspace(1, 10, 10) # specify alpha values\n",
    "inner_cv = KFold(n_splits=5, shuffle=False) # inner 5-fold cross-validation setup\n",
    "model = make_pipeline(\n",
    "    StandardScaler(), RidgeCV(alphas, fit_intercept=True, cv=inner_cv) # pipeline\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training encoding models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `RidgeCV` contains an inner cross-validation setup to find the best alpha, we will also set up an outer cross-validation loop to evaluate our encoding model. Here, we will use k = 2, meaning we will train on half of the data and evaluate on the other half. Within each fold, we will split the train and test dataset. Then we will standardize `Y` the same way we standardize `X` in the pipeline. We will then fit our model on the training dataset and use it to predict for the testing dataset. For evaluation, we will calculate correlation scores between `Y_preds`, the ECoG signal predicted by our model, and `Y_test`, the actual ECoG signal. The encoding model is trained and evaluated for each electrode and each lag.\n",
    "\n",
    "Note: this chunk of code takes a while to run..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_shape = epochs._data.shape[1:] # number of electrodes * number of lags\n",
    "\n",
    "def train_encoding(X, Y):\n",
    "\n",
    "    corrs = [] # empty array to store correlation results\n",
    "    kfold = KFold(2, shuffle=False) # outer 2-fold cross-validation setup\n",
    "    for train_index, test_index in kfold.split(X): # loop through folds\n",
    "\n",
    "        # Split train and test datasets\n",
    "        X1_train, X1_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        # Standardize Y\n",
    "        scaler = StandardScaler()\n",
    "        Y_train = scaler.fit_transform(Y_train)\n",
    "        Y_test = scaler.transform(Y_test)\n",
    "\n",
    "        model.fit(X1_train, Y_train) # Fit pipeline with transforms and ridge estimator\n",
    "        Y_preds = model.predict(X1_test) # Use trained model to predict on test set\n",
    "        corr = correlation_score(Y_test, Y_preds).reshape(epochs_shape) # Compute correlation score\n",
    "\n",
    "        if \"torch\" in get_backend().__name__: # if using gpu, transform tensor back to numpy\n",
    "            corr = corr.numpy(force=True)\n",
    "\n",
    "        corrs.append(corr) # append fold correlation results to final results\n",
    "    return np.stack(corrs)\n",
    "\n",
    "# set_backend(\"torch\") # resort to torch or numpy if cuda out of memory\n",
    "corrs_syntactic = train_encoding(X1, Y)\n",
    "corrs_embedding = train_encoding(X2, Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting encoding lag results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the correlations for one electrode on all lags. Again, we use `LGA10` as an example. We will plot the correlation for the syntactic features as blue and the correlation for the contextual word embeddings as red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = np.arange(-2 * 512, 2 * 512, 16) / 512 # specify the lags\n",
    "\n",
    "electrode = \"LGA10\"\n",
    "electrode_id = raw.info[\"ch_names\"].index(electrode) # get electrode index\n",
    "\n",
    "plt.axvline(0, c=\"k\", alpha=0.3, ls=\":\")\n",
    "plt.axhline(0, c=\"k\", alpha=0.3, ls=\":\")\n",
    "plt.plot(lags, corrs_syntactic.mean(0)[electrode_id], c=\"b\") # blue line\n",
    "plt.plot(lags, corrs_embedding.mean(0)[electrode_id], c=\"r\") # red line\n",
    "plt.xlabel(\"Lag (s)\")\n",
    "plt.ylabel(\"Encoding performance (r)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting encoding brainplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the max correlations for all electrodes on the brain. We will first get the coordinates of all electrodes from the raw ECoG data, resulting in `coords` with the shape of (number of electrodes * 3), where each electrode has a 3-dimensional MNI coordinate relative to the brain surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2loc = {ch['ch_name']: ch['loc'][:3] for ch in raw.info['chs']}\n",
    "coords = np.vstack([ch2loc[ch] for ch in raw.info['ch_names']])\n",
    "coords *= 1000  # nilearn likes to plot in meters, not mm\n",
    "coords.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take the max correlation for each electrode. Then, we will use the nilearn [`plot_markers`](https://nilearn.github.io/dev/modules/generated/nilearn.plotting.plot_markers.html#nilearn.plotting.plot_markers) function to plot electrodes on top of the brain glass schematics. To compare the encoding performance of our syntactic features and contextual word embeddings, we use the same colorbar scale for both brainplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_syntactic = corrs_syntactic.mean(0).max(-1)\n",
    "scores_embedding = corrs_embedding.mean(0).max(-1)\n",
    "print(scores_syntactic.shape, scores_embedding.shape)\n",
    "vmax = np.quantile(np.concatenate((scores_syntactic, scores_embedding)), .99)\n",
    "print(f\"Colorbar max correlation: {vmax}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, dpi=300, figsize=(8, 6))\n",
    "order = scores_syntactic.argsort()\n",
    "plot_markers(scores_syntactic[order], coords[order],\n",
    "             node_size=15, display_mode='lyr',\n",
    "             node_vmin=0, node_vmax=vmax,\n",
    "             figure=fig, axes=axes[0], alpha=0.8,\n",
    "             node_cmap='magma_r', colorbar=True)\n",
    "plot_markers(scores_embedding[order], coords[order],\n",
    "             node_size=15, display_mode='lyr',\n",
    "             node_vmin=0, node_vmax=vmax,\n",
    "             figure=fig, axes=axes[1], alpha=0.8,\n",
    "             node_cmap='magma_r', colorbar=True)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
